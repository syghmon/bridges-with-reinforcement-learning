{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T13:24:42.941671Z",
     "start_time": "2024-02-19T13:24:41.404776Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from aim import Figure, Image, Run\n",
    "\n",
    "from assembly_gym.envs.assembly_env import AssemblyEnv, Shape, Block\n",
    "from assembly_gym.envs.gym_env import AssemblyGym, sparse_reward, tower_setup, bridge_setup, hard_tower_setup\n",
    "from robotoddler.utils.actions import generate_actions, filter_actions\n",
    "from assembly_gym.utils.rendering import plot_assembly_env, render_assembly_env\n",
    "\n",
    "from robotoddler.training.successor_dqn import get_state_features, get_action_features, get_task_features,\\\n",
    "      update_target_net, train_policy_net, rollout_episode, EpsilonGreedy, log_episode\n",
    "from robotoddler.models.cv import ConvNet, SuccessorMLP\n",
    "\n",
    "from robotoddler.utils.replay_memory import ReplayBuffer\n",
    "from robotoddler.utils.utils import init_weights\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251dd0099916c909",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T13:24:43.267946Z",
     "start_time": "2024-02-19T13:24:42.956189Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# setup environment and test features\n",
    "width = height = 64\n",
    "\n",
    "env = AssemblyGym(**tower_setup(), \n",
    "                  reward_fct=sparse_reward,\n",
    "                  restrict_2d=True, \n",
    "                  assembly_env=AssemblyEnv(render=False))\n",
    "plot_assembly_env(env)\n",
    "\n",
    "obs, info = env.reset(**tower_setup())\n",
    "available_actions = [*generate_actions(env, x_discr_ground=np.linspace(0.2, 0.8, 5))]\n",
    "action = available_actions[3]\n",
    "\n",
    "# make the state a bit more interesting\n",
    "obs, _, _, _, info = env.step(action)\n",
    "available_actions = [*generate_actions(env, x_discr_ground=np.linspace(0.2, 0.8, 5))]\n",
    "\n",
    "\n",
    "# get all the features\n",
    "state_features, binary_features = get_state_features(obs, img_size=(width, height))\n",
    "task_features, obstacle_features = get_task_features(obs, img_size=(width, height))\n",
    "# obstacle_features = get_obstacle_features(env, width=width, height=height)\n",
    "action_features = get_action_features(env, available_actions, img_size=(width, height))\n",
    "# binary_features = get_binary_features(obs)\n",
    "\n",
    "# plotting / illustration\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "ax1.imshow(task_features.squeeze(), cmap='gray')\n",
    "ax1.set_title('Task Features')\n",
    "\n",
    "ax2.imshow(state_features.squeeze(), cmap='gray')\n",
    "ax2.set_title('State Features')\n",
    "\n",
    "ax3.imshow(obstacle_features.squeeze(), cmap='gray')\n",
    "ax3.set_title('Obstacle Features')\n",
    "\n",
    "ax4.imshow(action_features[4].squeeze(), cmap='gray')\n",
    "ax4.set_title('Action Features')\n",
    "\n",
    "env.assembly_env.disconnect_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b7f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the SuccessorNet\n",
    "model = SuccessorMLP(img_size=(width, height)).to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "model.apply(init_weights)\n",
    "model.eval()\n",
    "\n",
    "num_actions = 3\n",
    "# random input of size 512 x 512\n",
    "x = torch.rand(1, 1, width, height, device=device).expand((num_actions, -1, -1 ,-1))\n",
    "o = torch.rand(1, 1, width, height, device=device).expand((num_actions, -1, -1 ,-1))\n",
    "a = torch.rand(num_actions, 1, width, height, device=device)\n",
    "z = torch.ones(1, 1, width, height, device=device).expand((num_actions, -1, -1 ,-1))\n",
    "y = torch.ones(1, 6, device=device).expand((num_actions, -1))\n",
    "\n",
    "q_values, succ_img, succ_bin = model(x, y, a, z, o)\n",
    "print(succ_img)\n",
    "print(succ_bin)\n",
    "\n",
    "img = succ_img[0].softmax(dim=0)[1]\n",
    "features = succ_bin[0].softmax(dim=0)[1]\n",
    "\n",
    "# \n",
    "print(features)\n",
    "plt.imshow(img.detach().cpu().numpy(), cmap='gray', vmin=0, vmax=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6168d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the ConvNet\n",
    "model = ConvNet(4, img_size=(width, height)).to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "model.apply(init_weights)\n",
    "model.eval()\n",
    "\n",
    "num_actions = 3\n",
    "# random input of size 512 x 512\n",
    "x = torch.rand(1, 1, width, height, device=device).expand((num_actions, -1, -1 ,-1))\n",
    "o = torch.rand(1, 1, width, height, device=device).expand((num_actions, -1, -1 ,-1))\n",
    "a = torch.rand(num_actions, 1, width, height, device=device)\n",
    "z = torch.ones(1, 1, width, height, device=device).expand((num_actions, -1, -1 ,-1))\n",
    "y = torch.ones(1, 6, device=device).expand((num_actions, -1))\n",
    "\n",
    "q_values, _, features = model(x, y, a, z, o)\n",
    "print(q_values)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d2e5234fd731d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T13:34:50.285234Z",
     "start_time": "2024-02-19T13:34:50.284048Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Successor Feature Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce51ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# This code is taken from robotoddler.training.successor_dqn.py\n",
    "\n",
    "args = dict(\n",
    "    gamma=0.95,\n",
    "    batch_size=32,\n",
    "    evaluate_every=10,\n",
    "    num_episodes=1000,\n",
    "    learning_rate=0.0001,\n",
    "    num_training_steps=25,\n",
    "    tau=0.01,\n",
    "    loss_function='mse_q_values',\n",
    "    verbose=True,\n",
    "    seed=1,\n",
    "    tower_height=2,\n",
    "    max_steps=10,\n",
    "    image_size=(64, 64),\n",
    ")\n",
    "\n",
    "gamma = args['gamma']\n",
    "verbose = args['verbose']\n",
    "\n",
    "# random seed\n",
    "random.seed(args['seed'])\n",
    "np.random.seed(args['seed'])\n",
    "torch.manual_seed(args['seed'])\n",
    "\n",
    "# initialize everything\n",
    "episode = 0\n",
    "\n",
    "# setup function to generate environments\n",
    "x_discr_ground = np.linspace(0.2, 0.8, 3)\n",
    "def setup_fct():\n",
    "    tower_height = 0.02 + 0.05 * args['tower_height']\n",
    "    return tower_setup(targets=[(random.choice(x_discr_ground), 0, tower_height)])\n",
    "\n",
    "env = AssemblyGym(reward_fct=sparse_reward, max_steps=args['max_steps'], restrict_2d=True, assembly_env=AssemblyEnv(render=False))\n",
    "\n",
    "# Successor Feature MLP\n",
    "hidden_dims = [256, 128, 64, 128, 256]\n",
    "policy_net = SuccessorMLP(img_size=args['image_size'], hidden_dims=hidden_dims).to(device)\n",
    "target_net = SuccessorMLP(img_size=args['image_size'], hidden_dims=hidden_dims).to(device)\n",
    "\n",
    "# Standard Conv Net for predicting q values\n",
    "# policy_net = ConvNet(img_size=args['image_size']).to(device)\n",
    "# target_net = ConvNet(img_size=args['image_size']).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(policy_net.parameters(), lr=args['learning_rate'])\n",
    "policy_net.apply(init_weights)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "replay_buffer = ReplayBuffer(capacity=2000)\n",
    "\n",
    "aim_run = None\n",
    "# aim_run = aim.Run(experiment=\"SuccessorQLearning\", repo=args['aim_repo'])\n",
    "\n",
    "# define policies\n",
    "eps_greedy = EpsilonGreedy(eps_start=0.5, gamma=0.999, eps_end=0.05, episode=episode)\n",
    "greedy = lambda q, *args, **kwargs: torch.argmax(q)\n",
    "\n",
    "\n",
    "# training loop\n",
    "it = tqdm(range(episode + 1, episode + args['num_episodes'] + 1), disable=not verbose)\n",
    "for i in it:\n",
    "    # rollout episde\n",
    "    transitions, images = rollout_episode(env=env, \n",
    "                                    policy=eps_greedy.step(), \n",
    "                                    policy_net=policy_net, \n",
    "                                    setup_fct=setup_fct, \n",
    "                                    x_discr_ground=x_discr_ground, \n",
    "                                    img_size=args['image_size'],\n",
    "                                    device=device)\n",
    "    \n",
    "    # add transistions to replay buffer\n",
    "    replay_buffer.push(transitions)\n",
    "    \n",
    "    # train policy net for n steps\n",
    "    losses = train_policy_net(policy_net=policy_net, \n",
    "                target_net=target_net, \n",
    "                optimizer=optimizer, \n",
    "                loss_fct=args['loss_function'],\n",
    "                replay_buffer=replay_buffer, \n",
    "                gamma=gamma, \n",
    "                batch_size=args['batch_size'],\n",
    "                n_steps=args['num_training_steps'],\n",
    "                device=device,\n",
    "                verbose=False)\n",
    "\n",
    "    # update the target net\n",
    "    update_target_net(policy_net=policy_net, target_net=target_net, tau=args['tau'])\n",
    "\n",
    "    # logging\n",
    "    log_info, fig = log_episode(\n",
    "        episode=i, \n",
    "        transitions=transitions,\n",
    "        policy=eps_greedy,\n",
    "        losses=losses,\n",
    "        context='training',\n",
    "        gamma=gamma,\n",
    "        aim_run=aim_run\n",
    "    )\n",
    "    it.set_postfix(episode=i, **log_info)\n",
    "\n",
    "\n",
    "    # evaluate using greedy policy\n",
    "    if i % args['evaluate_every'] == 0:\n",
    "        # evaluate\n",
    "        transitions, images = rollout_episode(env=env, \n",
    "                                    policy=greedy, \n",
    "                                    policy_net=policy_net, \n",
    "                                    setup_fct=setup_fct, \n",
    "                                    x_discr_ground=x_discr_ground, \n",
    "                                    img_size=args['image_size'],\n",
    "                                    device=device,\n",
    "                                    log_images=True)\n",
    "\n",
    "        log_info, fig = log_episode(\n",
    "            episode=i,\n",
    "            transitions=transitions,\n",
    "            images=images,\n",
    "            log_images=True,\n",
    "            losses=None,\n",
    "            context='evaluation',\n",
    "            gamma=gamma,\n",
    "            aim_run=aim_run\n",
    "        )\n",
    "        print(log_info)\n",
    "        plt.show()\n",
    "        # plt.close(fig)\n",
    "\n",
    "        it.set_postfix(episode=episode, **log_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc03418a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
